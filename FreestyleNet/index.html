<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="A diffusion-based network for freestyle layout-to-image synthesis">
  <meta property="og:title" content="Freestyle Layout-to-Image Synthesis"/>
  <meta property="og:description" content="A diffusion-based network for freestyle layout-to-image synthesis"/>
  <meta property="og:url" content="https://essunny310.github.io/FreestyleNet/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/teaser.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image"> -->
  
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="FreestyleNet, FLIS, Layout-to-Image Synthesis, Text-to-Image Generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Freestyle Layout-to-Image Synthesis</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Freestyle Layout-to-Image Synthesis</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://github.com/essunny310">Han Xue</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                <a href="https://zhiwu-huang.github.io/">Zhiwu Huang</a><sup>2,3</sup>,
              </span>
              <span class="author-block">
                <a href="https://qianrusun.com/">Qianru Sun</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=jKIoTVoAAAAJ&hl=en">Li Song</a><sup>1,4</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.researchgate.net/profile/Wenjun-Zhang-29">Wenjun Zhang</a><sup>1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><small><sup>1</sup>School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University<br></small></span>
              <span class="author-block"><small><sup>2</sup>Singapore Management University&nbsp;&nbsp;</small></span>
              <span class="author-block"><small><sup>3</sup>University of Southampton<br></small></span>
              <span class="author-block"><small><sup>4</sup>MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University</small></span>
            </div>
            
            <div>
              <p style="font-size:19px;font-weight:bold;padding-top:5px;">CVPR 2023 (Highlight)</p>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                   <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2303.14412"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper (arXiv)</span>
                </a>
              </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

              <!-- Github link -->
              <span class="link-block">
                <a href="https://github.com/essunny310/FreestyleNet"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code (coming soon)</span>
              </a>
            </span>

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
                
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!--<!-- Teaser video-->
<!--<section class="hero teaser">
<!--  <div class="container is-max-desktop">
<!--    <div class="hero-body">
<!--      <video poster="" id="tree" autoplay controls muted loop height="100%">
<!--        <!-- Your video here -->
<!--        <source src="static/videos/banner_video.mp4"
<!--        type="video/mp4">
<!--      </video>
<!--      <h2 class="subtitle has-text-centered">
<!--        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
<!--      </h2>
<!--    </div>
<!--  </div>
<!--</section>
<!--<!-- End teaser video -->
  
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/teaser.png"
                   alt="Teaser."/>
      <p style="padding: 10px;" />
      <h2 class="subtitle has-text-centered">
        FreestyleNet - A new method that can generate diverse semantics onto a given layout.
      </h2>
    </div>
  </div>
</section>

  
  
<!-- Image carousel -->
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="subtitle has-text-centered">
        Here are some more freestyle layout-to-image synthesis (FLIS) results using our FreestyleNet
      </h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/dog.jpg" alt="Dog"/>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/car.jpg" alt="Car"/>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/horse.jpg" alt="Horse"/>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/building.jpg" alt="Building"/>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/sandwich.jpg" alt="Sandwich"/>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/boat.jpg" alt="Boat"/>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/dog-2.jpg" alt="Dog-2"/>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/flower.jpg" alt="Flower"/>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/suitcase.jpg" alt="Suitcase"/>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/bridge.jpg" alt="Bridge"/>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

  

<!-- Paper abstract -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Typical layout-to-image synthesis (LIS) models generate images for a closed set of semantic classes, e.g., 182 common objects in COCO-Stuff. 
            In this work, we explore the freestyle capability of the model, i.e., how far can it generate unseen semantics (e.g., classes, attributes, and styles) 
            onto a given layout, and call the task Freestyle LIS (FLIS). Thanks to the development of large-scale pre-trained language-image models, 
            a number of discriminative models (e.g., image classification and object detection) trained on limited base classes are empowered with 
            the ability of unseen class prediction. Inspired by this, we opt to leverage large-scale pre-trained text-to-image diffusion models 
            to achieve the generation of unseen semantics. The key challenge of FLIS is how to enable the diffusion model to synthesize images from 
            a specific layout which very likely violates its pre-learned knowledge, e.g., the model never sees "a unicorn sitting on a bench" during 
            its pre-training. To this end, we introduce a new module called Rectified Cross-Attention (RCA) that can be conveniently plugged in the diffusion model 
            to integrate semantic masks. This "plug-in" is applied in each cross-attention layer of the model to rectify the attention maps 
            between image and text tokens. The key idea of RCA is to enforce each text token to act on the pixels in a specified region, 
            allowing us to freely put a wide variety of semantics from pre-trained knowledge (which is general) onto the given layout (which is specific). 
            Extensive experiments show that the proposed diffusion network produces realistic and freestyle layout-to-image generation results 
            with diverse text inputs, which has a high potential to spawn a bunch of interesting applications.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

  

<section class="hero is-light is-small">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <h2 class="title is-3 has-text-centered">Method</h2>
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <div class="publication-img">
              <img id="Method" width="100%" src="static/images/method.jpg"/>
            </div>
          </div>
        </div>
      <div class="content has-text-justified">
        <p>
          By applying the proposed Rectified Cross-Attention (RCA) in Stable Diffusion, FreestyleNet is capable of generating high-fidelity images that faithfully reveal 
          the diverse semantics described in the text while conforming to the given layouts. RCA forces each text token to affect only pixels in the region specified by
          the layout, allowing us to put desired semantics from the text onto a layout. Note that RCA does not introduce any additional parameters into the pre-trained model.
        </p>
      </div>
    </div>
  </div>
</section>

  
  
<!-- FreeStyleNet vs. ControlNet -->
<!-- Image carousel -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">FreestyleNet vs. ControlNet</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/FreestyleNet_vs_ControlNet-1.jpg" alt="FreestyleNet_vs_ControlNet-1"/>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/FreestyleNet_vs_ControlNet-2.jpg" alt="FreestyleNet_vs_ControlNet-2"/>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/FreestyleNet_vs_ControlNet-3.jpg" alt="FreestyleNet_vs_ControlNet-3"/>
          </div>
      </div>
    </div>
  </section>
<!-- End image carousel -->

    
<section class="hero is-light is-small">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <h2 class="title is-3 has-text-centered">Comparison to LIS Baselines</h2>
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <div class="publication-img">
              <img id="LIS_Results" src="static/images/LIS_results.jpg"/>
            </div>
          </div>
        </div>
    </div>
  </div>
</section>
    


<!-- <!-- Youtube video -->
<!-- <section class="hero is-small is-light">
<!--   <div class="hero-body">
<!--     <div class="container">
<!--       <!-- Paper video. -->
<!--       <h2 class="title is-3">Video Presentation</h2>
<!--       <div class="columns is-centered has-text-centered">
<!--         <div class="column is-four-fifths">
<!--           
<!--           <div class="publication-video">
<!--             <!-- Youtube embed code here -->
<!--             <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
<!--           </div>
<!--         </div>
<!--       </div>
<!--     </div>
<!--   </div>
<!-- </section>
<!-- <!-- End youtube video -->


<!-- <!-- Video carousel -->
<!-- <section class="hero is-small">
<!--   <div class="hero-body">
<!--     <div class="container">
<!--       <h2 class="title is-3">Another Carousel</h2>
<!--       <div id="results-carousel" class="carousel results-carousel">
<!--         <div class="item item-video1">
<!--           <video poster="" id="video1" autoplay controls muted loop height="100%">
<!--             <!-- Your video file here -->
<!--             <source src="static/videos/carousel1.mp4"
<!--             type="video/mp4">
<!--           </video>
<!--         </div>
<!--         <div class="item item-video2">
<!--           <video poster="" id="video2" autoplay controls muted loop height="100%">
<!--             <!-- Your video file here -->
<!--             <source src="static/videos/carousel2.mp4"
<!--             type="video/mp4">
<!--           </video>
<!--         </div>
<!--         <div class="item item-video3">
<!--           <video poster="" id="video3" autoplay controls muted loop height="100%">\
<!--             <!-- Your video file here -->
<!--             <source src="static/videos/carousel3.mp4"
<!--             type="video/mp4">
<!--           </video>
<!--         </div>
<!--       </div>
<!--     </div>
<!--   </div>
<!-- </section>
<!-- <!-- End video carousel -->






<!-- <!-- Paper poster -->
<!-- <section class="hero is-small is-light">
<!--   <div class="hero-body">
<!--     <div class="container">
<!--       <h2 class="title">Poster</h2>
<!-- 
<!--       <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
<!--           </iframe>
<!--         
<!--       </div>
<!--     </div>
<!--   </section>
<!-- <!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <p>If you find our work useful, please cite our paper:</p>
        <pre><code>@inproceedings{xue2023freestylenet,
  title = {Freestyle Layout-to-Image Synthesis},
  author = {Xue, Han and Huang, Zhiwu and Sun, Qianru and Song, Li and Zhang, Wenjun},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  year = {2023},
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->



<section class="hero is-small">
  <div class="container is-max-desktop">
      <div class="section-title">
        <br>
        <h2 class="title is-3">Concurrent Works</h2>
      </div>
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
              <ul>
                  <li>Lvmin Zhang and Maneesh Agrawala. 
                  <a href="https://github.com/lllyasviel/ControlNet">Adding Conditional Control to Text-to-Image Diffusion Models.</a> 
                   arXiv preprint arXiv:2302.05543 (2023).</li>
                  <li>Omri Avrahami, Thomas Hayes, Oran Gafni, Sonal Gupta, Yaniv Taigman, Devi Parikh, Dani Lischinski, Ohad Fried, and Xi Yin. 
                  <a href="https://omriavrahami.com/spatext/">SpaText: Spatio-Textual Representation for Controllable Image Generation.</a> CVPR 2023. </li><br>
              </ul> 
        </div>
      </div>
    </div>
  </div>
</section>
  


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
          This page is based on the code from the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"> Academic-project-page-template</a>. 
            If you reuse this code, please credit them appropriately.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
